
--- Command Line Log Analysis ---


Log Analysing Methodology

â€¢ File Type 
â€¢ Scope of the File
â€¢ Time Range  
â€¢ IP Addresses 
â€¢ Sort IP Adresses
â€¢ Filter Duplicate Lines
â€¢ Filter Duplicate Lines (count uniq addresses)
â€¢ Specific URLs to the GET Request  
â€¢ Redirection to another URL
â€¢ HTTP Status Code
â€¢ User Agent


$ ls
$ file access.log 
$ ls -lh access.log 

$ wc access.log 
$ wc -l access.log 
$ wc -w access.log 
$ wc -b access.log 

$ head access.log 
$ head -n 1 access.log 
$ tail access.log 
$ tail -n 1 access.log 

$ cat access.log
$ more access.log 
$ less access.log 

$ cut access.log -d " " -f 1
$ cut access.log -d " " -f 7
$ cut access.log -d " " -f 9

$ cut access.log -d " " -f 1 | sort
$ cut access.log -d " " -f 1 | sort | uniq
$ cut access.log -d " " -f 1 | sort | uniq -c | sort -nr
$ cut access.log -d " " -f 1 | sort | uniq -c | grep -v " 1 " | sort -nr

$ cut -d "\"" -f 6 access.log 
$ cut -d "\"" -f 6 access.log  | sort | uniq -c | sort -nr

$ grep "Mozilla/5.0 (Hydra)" access.log 
$ grep "Mozilla/5.0 (Hydra)" access.log | awk '{print $1}'
$ grep "Mozilla/5.0 (Hydra)" access.log | awk '{print $1}' | sort | uniq -c


-- HTTP Response Code --

$ grep "Mozilla/5.0 (Hydra)" access.log | awk '{print $9}'
$ grep "Mozilla/5.0 (Hydra)" access.log | awk '$9 > 200'


-- Redirection --

$ grep "17/Jul/2024:18:49:02 -0400" access.log 
$ grep "17/Jul/2024:18:49:02 -0400" access.log | grep -v "login.php"
$ grep "Mozilla/5.0 (Hydra)" access.log | awk '{print $1}' | uniq -c



ðŸ§¾ Log Analyzing Methodology

1. File Type
Purpose: Check if the log file is plain text or another format.
Command: file access.log

2. Scope of the File
Purpose: Understand file size, length, and structure.
Commands: ls -lh access.log â€“ View file size,  wc access.log â€“ Count lines, words, bytes, head access.log, tail access.log â€“ Preview top/bottom, cat, less, more â€“ View content

3. Time Range
Purpose: Identify specific timestamps or time ranges.
Command: grep "17/Jul/2024:18:49:02 -0400" access.log

4. IP Addresses
Purpose: Extract IP addresses from each line.
Command: cut access.log -d " " -f 1

5. Sort IP Addresses
Purpose: Sort IP addresses alphabetically.
Command: cut access.log -d " " -f 1 | sort

6. Filter Duplicate Lines
Purpose: Get unique IP addresses.
Command: cut access.log -d " " -f 1 | sort | uniq

7. Filter Duplicate Lines (count uniq addresses)
Purpose: Count and sort how many times each IP appears (exclude single hits).
Command: cut access.log -d " " -f 1 | sort | uniq -c | sort -nr, cut access.log -d " " -f 1 | sort | uniq -c | grep -v " 1 " | sort -nr

8. Specific URLs to the GET Request
Purpose: Extract requested URLs (e.g., /index.html, /login.php).
Command: cut access.log -d " " -f 7

9. Redirection to another URL
Purpose: Look for 3xx HTTP status codes (redirects).
Command (implied): cut access.log -d " " -f 9 | grep "^3"

10. HTTP Status Code
Purpose: Analyze response status codes: 200 (OK), 404 (Not Found), etc.
Command: cut access.log -d " " -f 9, grep "Mozilla/5.0 (Hydra)" access.log | awk '{print $9}', awk '$9 > 200'

11. User Agent
Purpose: Identify clients/bots/tools making requests.
Command: cut -d "\"" -f 6 access.log, cut -d "\"" -f 6 access.log | sort | uniq -c | sort -nr, grep "Mozilla/5.0 (Hydra)" access.log


https://whois.domaintools.com/
https://talosintelligence.com/
https://www.kali.org/tools/hydra/
https://nmap.org/
